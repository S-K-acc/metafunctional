{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e2c09-43f8-4a46-b587-10c70e4a2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON, Dates, DelimitedFiles, Downloads, Flux, Printf, Plots #import libraries\n",
    "include(\"neural.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d372fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_inout(ρ_profiles, c1_profiles, ϕ_profiles; window_width, dx)\n",
    "    window_bins = 2 * round(Int, window_width / dx) + 1\n",
    "    ρ_windows_all = Vector{Vector{Float32}}()\n",
    "    c1_values_all = Vector{Float32}()\n",
    "    ϕ_functions_all = Vector{Vector{Float32}}()\n",
    "    for (ρ, c1, ϕ) in zip(ρ_profiles, c1_profiles, ϕ_profiles)\n",
    "        ρ_windows = generate_windows(ρ; window_bins)\n",
    "        ϕ_func = generate_phi(ϕ,ρ)\n",
    "        s = 40 # use every s'th training example if you want to speed up the process\n",
    "        for i in collect(1:s:length(c1)) \n",
    "            if !isfinite(c1[i])\n",
    "                continue\n",
    "            end\n",
    "            push!(ρ_windows_all, ρ_windows[:,i])\n",
    "            push!(c1_values_all, c1[i])\n",
    "            push!(ϕ_functions_all, ϕ_func[:,i])\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    reduce(hcat, ρ_windows_all), c1_values_all', reduce(hcat, ϕ_functions_all)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20c4ee",
   "metadata": {},
   "source": [
    "The following cell generates the training data from simulation data in the directory `Simulations`, where each file contains the (thermally scaled) local chemical potential $\\beta \\mu_\\mathrm{loc}(x) = \\beta (\\mu - V_\\mathrm{ext}(x))$, the density profile $\\rho(x)$ and the pair potential $\\beta \\phi(r)$.\n",
    "The function `read_sim_data` utilizes this data to calculate the one-body direct correlation function $c_1(x) = \\ln(\\rho(x))- \\beta \\mu_\\mathrm{loc}(x)$.\n",
    "The training sets containing the density-window and the pair potential as input and the $c_1$-value as output are created with the help of `generate_inout`.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0eff4-9edf-48f7-88b4-e0edb8f137dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads.download(\"https://myfiles.uni-bayreuth.de/filr/public-link/file-download/043490a392e1752f01931b17e3711848/93318/1417842602830201006/Simulations.tar\", \"Simulations.tar\")\n",
    "#run(`tar xf Simulations.tar`)\n",
    "datadir = \"Simulations\" #this contains training data\n",
    "ρ_profiles, c1_profiles, ϕ_profiles = read_sim_data(datadir);\n",
    "ρ_windows, c1_values, ϕ_functions = generate_inout(ρ_profiles, c1_profiles, ϕ_profiles; window_width=2.0, dx=0.01)\n",
    "size(ρ_windows), size(c1_values), size(ϕ_functions) #the last item in the tuple is the number of training samples we use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fec9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an example contained in 'Simulations'\n",
    "sim = rand(readdir(datadir, join = true))\n",
    "xs, βµloc, ρ, βϕ = eachcol(readdlm(sim))\n",
    "display(plot(xs, βµloc, ylabel = \"βµloc\", xlabel = \"x/σ\"))\n",
    "display(plot(xs, ρ, ylabel = \"ρ\", xlabel = \"x/σ\"))\n",
    "display(plot(xs[1:150], βϕ[1:150], ylabel = \"βϕ\", xlabel = \"r/σ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b1b2e",
   "metadata": {},
   "source": [
    "The cell below shows the training procedure of a neural metadensity functional with the previously prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5943f3-c73e-4ee3-a48b-11df758c17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "ρ_windows, c1_values, ϕ_functions = (ρ_windows, c1_values, ϕ_functions) |> gpu\n",
    "\n",
    "model = Chain(\n",
    "    Dense(size(vcat(ρ_windows, ϕ_functions))[1] => 512, softplus),\n",
    "    Dense(512 => 256, softplus),\n",
    "    Dense(256 => 128, softplus),\n",
    "    Dense(128 => 64, softplus),\n",
    "    Dense(64 => 32, softplus),\n",
    "    Dense(32 => 1) \n",
    ") |> gpu\n",
    "\n",
    "display(model) #architecture  \n",
    "\n",
    "opt = Flux.setup(Adam(), model) #optimizer\n",
    "\n",
    "loader = Flux.DataLoader((vcat(ρ_windows, ϕ_functions), c1_values), batchsize=256, shuffle=true)|> gpu  \n",
    "\n",
    "loss(m, x, y) = Flux.mse(m(x), y) #mean squared error \n",
    "metric(m, x, y) = Flux.mae(m(x), y) #mean absolute error\n",
    "get_learning_rate(epoch; initial=0.0001, rate=0.03, wait=5) = epoch < wait ? initial : initial * (1 - rate)^(epoch - wait)\n",
    "\n",
    "model_savefile = \"own_model.bson\"\n",
    "println(\"Saving model to $(model_savefile)\")\n",
    "for epoch in 1:150 \n",
    "    learning_rate = get_learning_rate(epoch)\n",
    "    Flux.adjust!(opt, learning_rate)      \n",
    "    @printf \"Epoch: %3i (learning_rate: %.2e)...\" epoch learning_rate; flush(stdout)\n",
    "    Flux.train!(loss, model, loader, opt) \n",
    "    @printf \" loss: %.5f, metric: %.5f\\n\" loss(model, vcat(ρ_windows, ϕ_functions), c1_values) metric(model, vcat(ρ_windows, ϕ_functions), c1_values); flush(stdout)\n",
    "    model = model |> cpu\n",
    "    BSON.@save model_savefile model\n",
    "    model = model |> gpu\n",
    "end\n",
    "\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
