{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6e2c09-43f8-4a46-b587-10c70e4a2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "WARNING: could not import LinearAlgebra.libblastrampoline into StaticArrays\n"
     ]
    }
   ],
   "source": [
    "using BSON, Dates, DelimitedFiles, Downloads, Flux, Printf\n",
    "include(\"neural.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14e2464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_inout (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_inout(ρ_profiles, c1_profiles, ϕ_profiles; window_width, dx)\n",
    "    window_bins = 2 * round(Int, window_width / dx) + 1\n",
    "    ρ_windows_all = Vector{Vector{Float32}}()\n",
    "    c1_values_all = Vector{Float32}()\n",
    "    ϕ_functions_all = Vector{Vector{Float32}}()\n",
    "    for (ρ, c1, ϕ) in zip(ρ_profiles, c1_profiles, ϕ_profiles)\n",
    "        ρ_windows = generate_windows(ρ; window_bins)\n",
    "        ϕ_func = generate_phi(ϕ,ρ)\n",
    "        s = 40 \n",
    "        for i in collect(1:s:length(c1)) \n",
    "            if !isfinite(c1[i])\n",
    "                continue\n",
    "            end\n",
    "            push!(ρ_windows_all, ρ_windows[:,i])\n",
    "            push!(c1_values_all, c1[i])\n",
    "            push!(ϕ_functions_all, ϕ_func[:,i])\n",
    "            \n",
    "            #push!(ρ_windows_all, reverse(ρ_windows[:,i]))\n",
    "            #push!(c1_values_all, c1[i])\n",
    "            #push!(ϕ_functions_all, ϕ_func[:,i])\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    reduce(hcat, ρ_windows_all), c1_values_all', reduce(hcat, ϕ_functions_all)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd0eff4-9edf-48f7-88b4-e0edb8f137dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((401, 270949), (1, 270949), (150, 270949))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Downloads.download(\"https://myfiles.uni-bayreuth.de/filr/public-link/file-download/043490a392e1752f01931b17e3711848/93318/1417842602830201006/Simulations.tar\", \"Simulations.tar\")\n",
    "run(`tar xf Simulations.tar`)\n",
    "datadir = \"Simulations\"\n",
    "ρ_profiles, c1_profiles, ϕ_profiles = read_sim_data(datadir);\n",
    "ρ_windows, c1_values, ϕ_functions = generate_inout(ρ_profiles, c1_profiles, ϕ_profiles; window_width=2.0, dx=0.01)\n",
    "size(ρ_windows), size(c1_values), size(ϕ_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5943f3-c73e-4ee3-a48b-11df758c17e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(551 => 512, softplus),          \u001b[90m# 282_624 parameters\u001b[39m\n",
       "  Dense(512 => 256, softplus),          \u001b[90m# 131_328 parameters\u001b[39m\n",
       "  Dense(256 => 128, softplus),          \u001b[90m# 32_896 parameters\u001b[39m\n",
       "  Dense(128 => 64, softplus),           \u001b[90m# 8_256 parameters\u001b[39m\n",
       "  Dense(64 => 32, softplus),            \u001b[90m# 2_080 parameters\u001b[39m\n",
       "  Dense(32 => 1),                       \u001b[90m# 33 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 12 arrays, \u001b[39m457_217 parameters, 1.656 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to model_test.bson\n",
      "Epoch:   1 (learning_rate: 1.00e-04)... loss: 0.23144, metric: 0.18973\n",
      "Epoch:   2 (learning_rate: 1.00e-04)... loss: 0.13739, metric: 0.17833\n",
      "Epoch:   3 (learning_rate: 1.00e-04)... loss: 0.08051, metric: 0.14319\n",
      "Epoch:   4 (learning_rate: 1.00e-04)... loss: 0.09872, metric: 0.13872\n",
      "Epoch:   5 (learning_rate: 1.00e-04)... loss: 0.07621, metric: 0.12498\n",
      "Epoch:   6 (learning_rate: 9.70e-05)... loss: 0.05497, metric: 0.11087\n",
      "Epoch:   7 (learning_rate: 9.41e-05)... loss: 0.05415, metric: 0.12007\n",
      "Epoch:   8 (learning_rate: 9.13e-05)..."
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] actual_alloc(bytes::Int64; async::Bool, stream::CuStream)",
      "    @ CUDA ~/.julia/packages/CUDA/s5N6v/src/pool.jl:71",
      "  [2] #992",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/pool.jl:428 [inlined]",
      "  [3] retry_reclaim(f::CUDA.var\"#992#994\"{CuStream, Int64}, isfailed::typeof(isnothing))",
      "    @ CUDA ~/.julia/packages/CUDA/s5N6v/src/pool.jl:348",
      "  [4] macro expansion",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/pool.jl:427 [inlined]",
      "  [5] macro expansion",
      "    @ ./timing.jl:382 [inlined]",
      "  [6] #_alloc#991",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/pool.jl:424 [inlined]",
      "  [7] #alloc#990",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/pool.jl:409 [inlined]",
      "  [8] alloc",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/pool.jl:403 [inlined]",
      "  [9] CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}(#unused#::UndefInitializer, dims::Tuple{Int64, Int64})",
      "    @ CUDA ~/.julia/packages/CUDA/s5N6v/src/array.jl:93",
      " [10] CuArray",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/array.jl:176 [inlined]",
      " [11] CuArray",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/array.jl:187 [inlined]",
      " [12] similar",
      "    @ ./abstractarray.jl:841 [inlined]",
      " [13] similar",
      "    @ ./abstractarray.jl:840 [inlined]",
      " [14] similar",
      "    @ ~/.julia/packages/CUDA/s5N6v/src/broadcast.jl:11 [inlined]",
      " [15] copy",
      "    @ ~/.julia/packages/GPUArrays/5XhED/src/host/broadcast.jl:37 [inlined]",
      " [16] materialize",
      "    @ ./broadcast.jl:860 [inlined]",
      " [17] rrule(#unused#::typeof(Base.Broadcast.broadcasted), #unused#::typeof(softplus), x::CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ NNlib ~/.julia/packages/NNlib/Fg3DQ/src/activations.jl:892",
      " [18] rrule",
      "    @ ~/.julia/packages/ChainRulesCore/6Pucz/src/rules.jl:138 [inlined]",
      " [19] chain_rrule",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/chainrules.jl:224 [inlined]",
      " [20] macro expansion",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:113 [inlined]",
      " [21] _pullback",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:113 [inlined]",
      " [22] _pullback",
      "    @ ~/.julia/packages/Flux/n3cOc/src/layers/basic.jl:174 [inlined]",
      " [23] _pullback",
      "    @ ~/.julia/packages/Flux/n3cOc/src/layers/basic.jl:53 [inlined]",
      " [24] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}, ::CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0",
      " [25] _pullback",
      "    @ ~/.julia/packages/Flux/n3cOc/src/layers/basic.jl:51 [inlined]",
      " [26] _pullback",
      "    @ ./In[4]:19 [inlined]",
      " [27] _apply",
      "    @ ./boot.jl:816 [inlined]",
      " [28] adjoint",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/lib/lib.jl:203 [inlined]",
      " [29] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/M4xmc/src/adjoint.jl:67 [inlined]",
      " [30] _pullback",
      "    @ ~/.julia/packages/Flux/n3cOc/src/train.jl:107 [inlined]",
      " [31] _pullback(ctx::Zygote.Context{false}, f::Flux.Train.var\"#4#5\"{typeof(loss), Tuple{CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, LinearAlgebra.Adjoint{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}, args::Chain{Tuple{Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface2.jl:0",
      " [32] pullback(f::Function, cx::Zygote.Context{false}, args::Chain{Tuple{Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface.jl:90",
      " [33] pullback",
      "    @ ~/.julia/packages/Zygote/nyzjS/src/compiler/interface.jl:88 [inlined]",
      " [34] withgradient(f::Function, args::Chain{Tuple{Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}})",
      "    @ Zygote ~/.julia/packages/Zygote/nyzjS/src/compiler/interface.jl:205",
      " [35] macro expansion",
      "    @ ~/.julia/packages/Flux/n3cOc/src/train.jl:107 [inlined]",
      " [36] macro expansion",
      "    @ ~/.julia/packages/ProgressLogging/6KXlp/src/ProgressLogging.jl:328 [inlined]",
      " [37] train!(loss::Function, model::Chain{Tuple{Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}, data::MLUtils.DataLoader{MLUtils.MappedData{:auto, typeof(gpu), Tuple{CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, LinearAlgebra.Adjoint{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}, Random._GLOBAL_RNG, Val{nothing}}, opt::NamedTuple{(:layers,), Tuple{NTuple{6, NamedTuple{(:weight, :bias, :σ), Tuple{Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, Tuple{Float64, Float64}}}, Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Tuple{Float64, Float64}}}, Tuple{}}}}}}; cb::Nothing)",
      "    @ Flux.Train ~/.julia/packages/Flux/n3cOc/src/train.jl:105",
      " [38] train!(loss::Function, model::Chain{Tuple{Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(identity), CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}, data::MLUtils.DataLoader{MLUtils.MappedData{:auto, typeof(gpu), Tuple{CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, LinearAlgebra.Adjoint{Float32, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}, Random._GLOBAL_RNG, Val{nothing}}, opt::NamedTuple{(:layers,), Tuple{NTuple{6, NamedTuple{(:weight, :bias, :σ), Tuple{Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, Tuple{Float64, Float64}}}, Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, Tuple{Float64, Float64}}}, Tuple{}}}}}})",
      "    @ Flux.Train ~/.julia/packages/Flux/n3cOc/src/train.jl:102",
      " [39] top-level scope",
      "    @ ./In[4]:29"
     ]
    }
   ],
   "source": [
    "using CUDA\n",
    "ρ_windows, c1_values, ϕ_functions = (ρ_windows, c1_values, ϕ_functions) |> gpu\n",
    "\n",
    "model = Chain(\n",
    "    Dense(size(vcat(ρ_windows, ϕ_functions))[1] => 512, softplus),\n",
    "    Dense(512 => 256, softplus),\n",
    "    Dense(256 => 128, softplus),\n",
    "    Dense(128 => 64, softplus),\n",
    "    Dense(64 => 32, softplus),\n",
    "    Dense(32 => 1) \n",
    ") |> gpu\n",
    "\n",
    "display(model)  \n",
    "\n",
    "opt = Flux.setup(Adam(), model) \n",
    "\n",
    "loader = Flux.DataLoader((vcat(ρ_windows, ϕ_functions), c1_values), batchsize=256, shuffle=true)|> gpu  \n",
    "\n",
    "loss(m, x, y) = Flux.mse(m(x), y)  \n",
    "metric(m, x, y) = Flux.mae(m(x), y)  \n",
    "get_learning_rate(epoch; initial=0.0001, rate=0.03, wait=5) = epoch < wait ? initial : initial * (1 - rate)^(epoch - wait)\n",
    "\n",
    "model_savefile = \"model_test.bson\"\n",
    "println(\"Saving model to $(model_savefile)\")\n",
    "for epoch in 1:150 \n",
    "    learning_rate = get_learning_rate(epoch)\n",
    "    Flux.adjust!(opt, learning_rate)      \n",
    "    @printf \"Epoch: %3i (learning_rate: %.2e)...\" epoch learning_rate; flush(stdout)\n",
    "    Flux.train!(loss, model, loader, opt) \n",
    "    @printf \" loss: %.5f, metric: %.5f\\n\" loss(model, vcat(ρ_windows, ϕ_functions), c1_values) metric(model, vcat(ρ_windows, ϕ_functions), c1_values); flush(stdout)\n",
    "    model = model |> cpu\n",
    "    BSON.@save model_savefile model\n",
    "    model = model |> gpu\n",
    "end\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71dfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
